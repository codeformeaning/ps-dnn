[sparse_dict]
emb_dim=1

[layers]
layers=fc:32,relu:-1,fc:1,sigmoid:-1

[loss]
#cross_entropy,mse,special_mse
loss=cross_entropy

[optimizer]
#adam,sgd
optimizer=adam
learning_rate=0.05

[train]
epoch=10
batch_size=128

[test]
batch_size=500000
